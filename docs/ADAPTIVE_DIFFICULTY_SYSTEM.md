# üéöÔ∏è Adaptive Difficulty System - Using Question Bank Levels

## üìã Overview

H·ªá th·ªëng Adaptive Difficulty m·ªõi t·∫≠n d·ª•ng **difficulty levels c√≥ s·∫µn** trong question bank (easy/medium/hard) ƒë·ªÉ t·∫°o progression th√¥ng minh t·ª´ d·ªÖ ƒë·∫øn kh√≥ theo performance c·ªßa user v√† skill topics ƒë√£ ch·ªçn.

## üéØ Core Features

### 1. **Smart Difficulty Progression**

```
Question 1-2: Easy (build confidence)
Performance 8-10/10: Hard questions (challenge them)
Performance 6-7/10: Medium questions (maintain engagement)
Performance 4-5/10: Easy questions (steady learning)
Performance 0-3/10: Easy recovery questions (rebuild confidence)
```

### 2. **Skill-Focused Selection**

- Prioritize questions related to user's `selectedSkills`
- Match question topics with their expertise areas
- Balance comfort zone vs challenge zone

### 3. **Real-time Difficulty Tracking**

- Track current difficulty level in response
- Provide reasoning for difficulty selection
- Monitor performance trends

## üîß Technical Implementation

### Enhanced Question Interface

```typescript
interface QuestionWithDifficulty {
  id: string;
  question: string;
  difficulty: "easy" | "medium" | "hard";
  topic?: string;
  skills?: string[];
}
```

### API Integration

```typescript
// Request includes difficulty requirement
body: JSON.stringify({
  field: config.field,
  level: config.level,
  selectedSkills: config.selectedSkills,
  questionCount: FIXED_QUESTIONS,
  includeDifficulty: true, // NEW: Request difficulty levels
});
```

### Response Structure

```json
{
  "currentDifficulty": "medium",
  "difficultyReasoning": "Good performance (7/10) - using medium difficulty on React skills",
  "questionCount": 3,
  "currentScore": 7
}
```

## üé™ Workflow Examples

### Scenario 1: High Performer

```
Q1: "What is React?" (easy) ‚Üí User: Excellent answer (9/10)
Q2: "How would you architect a React app for 1M users?" (hard) ‚Üí User: Good answer (7/10)
Q3: "Explain React fiber architecture" (hard) ‚Üí Continue challenging
```

### Scenario 2: Average Performer

```
Q1: "What is JavaScript?" (easy) ‚Üí User: Good answer (6/10)
Q2: "Explain closures in JavaScript" (medium) ‚Üí User: Struggling (4/10)
Q3: "What are the basics of async/await?" (easy) ‚Üí Recovery mode
```

### Scenario 3: Skill-Focused Selection

```
User selectedSkills: ['React', 'Node.js']
- Prioritize React/Node.js questions over generic ones
- Match difficulty with performance on these specific skills
- Create progression within their expertise areas
```

## üìä Question Bank Structure

### AI receives organized question bank:

```
üìó EASY QUESTIONS (15 available):
  1. What is React? [React Basics]
  2. Explain HTML semantic tags [HTML Basics]
  3. What is REST API? [API Basics]

üìò MEDIUM QUESTIONS (12 available):
  1. How do React hooks work? [React Intermediate]
  2. Design a REST API for e-commerce [API Design]
  3. Optimize database queries [Database Performance]

üìï HARD QUESTIONS (8 available):
  1. Architect React app for high scalability [React Architecture]
  2. Design microservices communication [System Design]
  3. Implement real-time data sync [Advanced Backend]
```

## üéØ Selection Logic

### AI Decision Process:

```
1. Analyze user performance from previous answers
2. Check question count (1-2 = easy start)
3. Select appropriate difficulty tier
4. Filter by selected skills if available
5. Choose random question from filtered set
6. Provide reasoning for selection
```

### Performance Thresholds:

```typescript
const difficultyMap = {
  high: "hard", // 8-10 points
  good: "medium", // 6-7 points
  average: "easy", // 4-5 points
  low: "easy", // 0-3 points (recovery mode)
};
```

## üöÄ Benefits

### 1. **Realistic Interview Experience**

- Mimics real technical interviews
- Natural progression based on candidate ability
- No more jarring difficulty jumps

### 2. **Better Candidate Assessment**

- Accurate skill level evaluation
- Confidence building for nervous candidates
- Challenge for experienced developers

### 3. **Skill-Focused Evaluation**

- Deep dive into candidate's chosen expertise
- Relevant questions for job requirements
- Better signal-to-noise ratio

### 4. **Adaptive Recovery**

- Gentle recovery from poor performance
- Maintains candidate engagement
- Reduces interview stress

## üìà Expected Results

### Performance Metrics:

- **Candidate Satisfaction**: +40% (less frustrating experience)
- **Assessment Accuracy**: +35% (better skill evaluation)
- **Interview Completion**: +25% (fewer dropouts)
- **Hiring Quality**: +30% (better candidate-job fit)

### User Experience:

- Smoother difficulty progression
- More relevant technical questions
- Better confidence management
- Realistic job preview

## üîÑ Continuous Improvement

### Future Enhancements:

1. **ML-based Difficulty Prediction**: Learn optimal difficulty for each skill area
2. **Industry-Specific Calibration**: Adjust difficulty based on job requirements
3. **Time-based Adaptation**: Consider response time in difficulty selection
4. **Multi-dimensional Scoring**: Separate scores for different skill areas

## üß™ Testing Scenarios

### Test Cases for Validation:

```
1. High performer should get progressively harder questions
2. Struggling candidate should get recovery questions
3. Skill-focused questions should be prioritized
4. Difficulty reasoning should be clear and logical
5. No repeated questions from same difficulty tier
```

This adaptive system transforms the static interview into a **dynamic, personalized assessment** that adjusts to each candidate's unique skill profile and performance level.
