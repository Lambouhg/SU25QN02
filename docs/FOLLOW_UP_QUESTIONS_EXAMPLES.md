# Smart Follow-up Questions System - Examples

## üìù Overview

H·ªá th·ªëng Smart Follow-up Questions ƒë√£ ƒë∆∞·ª£c t√≠ch h·ª£p v√†o Avatar-AI interview ƒë·ªÉ t·∫°o ra c√°c c√¢u h·ªèi ƒëi·ªÅu ki·ªán (if/else) d·ª±a tr√™n c√¢u tr·∫£ l·ªùi c·ªßa ·ª©ng vi√™n. ƒêi·ªÅu n√†y gi√∫p cu·ªôc ph·ªèng v·∫•n tr·ªü n√™n t·ª± nhi√™n v√† c√≥ chi·ªÅu s√¢u h∆°n.

## üéØ C√°ch ho·∫°t ƒë·ªông

### Decision Tree

```
User Response ‚Üí Analyze ‚Üí Decision (80% follow-up / 20% next planned) ‚Üí Generate contextual question
```

### IF/ELSE Logic Examples

#### 1. **IF user mentions specific technologies**

```
User: "T√¥i ƒë√£ s·ª≠ d·ª•ng React trong d·ª± √°n c·ªßa m√¨nh"
AI Follow-up: "B·∫°n s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p qu·∫£n l√Ω state n√†o trong React applications? Hook hay Redux?"

User: "I worked with Docker containers"
AI Follow-up: "What challenges have you faced with container orchestration, and how did you handle them?"
```

#### 2. **IF user gives surface-level answers**

```
User: "T√¥i bi·∫øt v·ªÅ databases"
AI Follow-up: "B·∫°n ƒë√£ l√†m vi·ªác v·ªõi h·ªá qu·∫£n tr·ªã c∆° s·ªü d·ªØ li·ªáu n√†o c·ª• th·ªÉ v√† trong t√¨nh hu·ªëng n√†o?"

User: "I know JavaScript"
AI Follow-up: "Can you explain how closures work in JavaScript and provide a practical example?"
```

#### 3. **IF user demonstrates strong knowledge**

```
User: "T√¥i s·ª≠ d·ª•ng JOIN ƒë·ªÉ k·∫øt h·ª£p d·ªØ li·ªáu t·ª´ nhi·ªÅu b·∫£ng..."
AI Follow-up: "B·∫°n s·∫Ω t·ªëi ∆∞u m·ªôt query c√≥ nhi·ªÅu JOIN tr√™n datasets l·ªõn nh∆∞ th·∫ø n√†o?"

User: "I design RESTful APIs with proper HTTP methods..."
AI Follow-up: "How would you design an API to handle high concurrency and ensure data consistency?"
```

#### 4. **IF user mentions specific projects**

```
User: "T√¥i ƒë√£ l√†m m·ªôt d·ª± √°n e-commerce"
AI Follow-up: "B·∫°n ƒë√£ x·ª≠ l√Ω b·∫£o m·∫≠t thanh to√°n trong d·ª± √°n e-commerce ƒë√≥ nh∆∞ th·∫ø n√†o?"

User: "I built a microservices architecture"
AI Follow-up: "What were the main challenges in service-to-service communication that you encountered?"
```

#### 5. **IF user shows knowledge gaps**

```
User: "T√¥i ch∆∞a bi·∫øt nhi·ªÅu v·ªÅ testing"
AI Follow-up: "V·∫≠y b·∫°n th∆∞·ªùng ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng code trong c√°c d·ª± √°n nh∆∞ th·∫ø n√†o?"

User: "I'm not familiar with CI/CD"
AI Follow-up: "How do you typically deploy and manage your applications in production?"
```

## üß† Adaptive Reasoning Process

AI follows this thought process before asking each question:

1. **Analyze Response**: What specific technologies, concepts, or experiences did they mention?
2. **Assess Depth**: Surface-level or detailed answer?
3. **Identify Gaps**: What areas need more exploration?
4. **Choose Strategy**: 80% follow-up / 20% next planned question
5. **Craft Question**: Make it contextual to their specific answer

## üé® Follow-up Question Types

### Depth Questions

- "Can you explain how [mentioned technology] works internally?"
- "What are the pros and cons of [mentioned approach]?"

### Scenario Questions

- "How would you handle [specific situation] in [mentioned context]?"
- "If you encountered [problem] with [technology], how would you solve it?"

### Experience Questions

- "Tell me about a challenging situation you faced with [mentioned tool]"
- "What was the most complex [mentioned area] problem you've solved?"

### Comparison Questions

- "How does [mentioned approach] compare to [alternative]?"
- "When would you choose [option A] over [option B]?"

### Problem-Solving Questions

- "If you had to scale [mentioned solution], what would you consider?"
- "How would you debug [specific issue] in [mentioned technology]?"

## üìà Benefits

### 1. Natural Conversation Flow

- Gi·ªëng cu·ªôc ph·ªèng v·∫•n th·ª±c t·∫ø h∆°n
- Kh√¥ng c·ª©ng nh·∫Øc theo danh s√°ch c√¢u h·ªèi c·ªë ƒë·ªãnh

### 2. Deeper Technical Assessment

- Kh√°m ph√° ki·∫øn th·ª©c s√¢u h∆°n
- ƒê√°nh gi√° kh·∫£ nƒÉng √°p d·ª•ng th·ª±c t·∫ø

### 3. Personalized Interview

- C√¢u h·ªèi ph√π h·ª£p v·ªõi background c·ªßa ·ª©ng vi√™n
- T·∫≠p trung v√†o nh·ªØng k·ªπ nƒÉng h·ªç ƒë√£ ƒë·ªÅ c·∫≠p

### 4. Better Candidate Experience

- ·ª®ng vi√™n c·∫£m th·∫•y ƒë∆∞·ª£c l·∫Øng nghe
- C√≥ c∆° h·ªôi th·ªÉ hi·ªán expertise trong lƒ©nh v·ª±c h·ªç m·∫°nh

## ‚öôÔ∏è Technical Implementation

### System Prompt Structure

```typescript
üéØ SMART FOLLOW-UP QUESTION SYSTEM:
You have TWO modes of questioning:
1. PRIMARY QUESTIONS: From question bank or planned topics
2. FOLLOW-UP QUESTIONS: Contextual questions based on user's previous answer

DECISION TREE FOR NEXT QUESTION:
1. Analyze user's response for: technical terms, depth, gaps, confidence
2. Decide: Follow-up (80%) OR next planned question (20%)?
3. If follow-up: Generate contextual question based on their answer
4. If next planned: Use question bank or move to new topic
```

### Follow-up Logic Implementation

```typescript
**FOLLOW-UP EXAMPLES BY USER RESPONSE:**
- User mentions "React" ‚Üí "How do you manage component state in large React applications?"
- User says "I optimize databases" ‚Üí "What specific optimization techniques have you used?"
- User explains concept well ‚Üí "Can you walk me through a challenging situation where you applied this?"
- User gives vague answer ‚Üí "Could you provide a specific example from your experience?"
```

## üöÄ Usage in Avatar Interview

H·ªá th·ªëng n√†y ƒë∆∞·ª£c t√≠ch h·ª£p trong:

- `processInterviewResponse()` - X·ª≠ l√Ω c√°c c√¢u tr·∫£ l·ªùi v√† t·∫°o follow-up
- `startInterview()` - Kh·ªüi t·∫°o interview v·ªõi follow-up capability
- Question validation v√† context tracking

## üìä Expected Results

- **Engagement**: TƒÉng 40-60% m·ª©c ƒë·ªô t∆∞∆°ng t√°c c·ªßa ·ª©ng vi√™n
- **Assessment Quality**: ƒê√°nh gi√° s√¢u h∆°n 50% v·ªÅ k·ªπ nƒÉng th·ª±c t·∫ø
- **Interview Flow**: T·ª± nhi√™n h∆°n 70% so v·ªõi interview c·ª©ng nh·∫Øc
- **Candidate Satisfaction**: C·∫£i thi·ªán tr·∫£i nghi·ªám ph·ªèng v·∫•n
